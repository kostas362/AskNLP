{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362028c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import spacy\n",
    "\n",
    "#Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î¼Îµ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î¿ Ï€Î¿Ï… Î´Î¹Î±Î¼ÏŒÏÏ†Ï‰ÏƒÎ±\n",
    "def auto_reconstruct(text):\n",
    "    #kÎ±Î½ÏŒÎ½ÎµÏ‚ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î¿Ï… Î³Î¹Î± Î±Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î®\n",
    "    text = re.sub(r\"hope you too, to enjoy\", \"I hope you enjoy\", text)\n",
    "    text = re.sub(r\"Thank your message\", \"Thank you for your message\", text)\n",
    "    text = re.sub(r\"as his next contract checking\", \"regarding his upcoming contract review\", text)\n",
    "    text = re.sub(r\"although bit delay\", \"although there was a slight delay\", text)\n",
    "    text = re.sub(r\"to show our words to the doctor\", \"to forward our message to the doctor\", text)\n",
    "    text = re.sub(r\"for paper and cooperation\", \"for the paper and collaboration\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "#Î¼Î¿Î½Ï„Î­Î»Î¿ Î±Î³Î³Î»Î¹ÎºÏÎ½\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#Î±Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î· Î¼Îµ spacy\n",
    "def spacy_reconstruct(text):\n",
    "    doc = nlp(text)\n",
    "    reconstructed_sentences = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = [token.text for token in sent if not token.is_punct or token.text == '.']\n",
    "        sentence = ' '.join(tokens).strip()\n",
    "        reconstructed_sentences.append(sentence)\n",
    "\n",
    "    return ' '.join(reconstructed_sentences)\n",
    "\n",
    "def spacy_auto_reconstruct(text):\n",
    "    #ÎºÎ±Î»ÎµÎ¹ Ï„Î¿ auto_reconstruct ÎºÎ±Î¹ Î¼ÎµÏ„Î± Î¸Î± ÎºÎ±Î»Î­ÏƒÎµÎ¹ ÎºÎ±Î¹ Ï„Î¿ spacy\n",
    "    text = auto_reconstruct(text)\n",
    "    \n",
    "    #ÎºÎ±Î½ÎµÎ¹ load Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    reconstructed_sentences = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        tokens = [token.text for token in sent if not token.is_punct or token.text == '.']\n",
    "        sentence = ' '.join(tokens).strip()\n",
    "        reconstructed_sentences.append(sentence)\n",
    "\n",
    "    return ' '.join(reconstructed_sentences)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"ramsrigouthamg/t5_paraphraser\")\n",
    "\n",
    "#Î±Î½Î±ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…Î· Î¼Îµ transformers\n",
    "def transformers_reconstruct(text):\n",
    "    input_text = \"paraphrase: \" + text.strip()\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=128,\n",
    "        num_beams=5,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "    if not decoded or decoded.lower().startswith(\"paraphrase\") or decoded == text.strip():\n",
    "        return text.strip()\n",
    "    return decoded\n",
    "\n",
    "#ÏƒÏ€Î±ÎµÎ¹ Ï„Î¿ ÎºÎµÎ¹Î¼ÎµÎ½Î¿ ÏƒÎµ chunks Î±Ï€ Î¿Ï„Î¹ Î¸Ï…Î¼Î±Î¼Î±Î¹\n",
    "def chunk_and_paraphrase(text, max_chunk_words=45):\n",
    "    words = text.split()\n",
    "    chunks = [' '.join(words[i:i+max_chunk_words]) for i in range(0, len(words), max_chunk_words)]\n",
    "    full_output = []\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        print(f\"\\nğŸ”¹ Paraphrasing chunk {idx+1}:\")\n",
    "        result = transformers_reconstruct(chunk)\n",
    "        print(f\"[{idx+1}] {result}\")\n",
    "        full_output.append(result)\n",
    "\n",
    "    return ' '.join(full_output)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
